[train]
batch_size = 12
type_of_loss = cross_entropy_loss

optimizer = adam
learning_rate =	1e-4

weight_decay = 1e-4

momentum = 1

gamma = 0.95
step_size = 1

pre_train = 0

epoch = 1024


[model]
name = Encoder_Distance

hidden_size = 128
filter = 64

# encoder = textcnn
encoder = lstm

min_gram = 2
max_gram = 5

num_layers = 1

filters = 32

[reader]
max_queue_size = 10
train_reader_num = 1
valid_reader_num = 1

[data]
formatter = CAIL_Formatter

train_data_path = /data/disk1/private/xcj/LAPP/data/cut_data
train_file_list = cail_small_shuffle.txt

valid_data_path = /data/disk1/private/xcj/LAPP/data/cut_data
valid_file_list = valid_small_shuffle.txt 


word2id = /data/disk1/private/xcj/LAPP/data/word2id.txt

need_word2vec = False

max_len = 490


[output]
model_path = /data/disk1/private/xcj/LAPP/model
model_name = Encoder_Distance
tensorboard_path = /data/disk1/private/xcj/LAPP/tensorboard
test_time = 1
output_time = 1


