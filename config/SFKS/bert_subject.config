[train]
batch_size = 16
type_of_loss = cross_entropy_loss

optimizer = bert_adam
learning_rate = 1e-4

weight_decay = 0.01

gamma = 1
step_size = 10

[model]
name = Bert

bert_path = /data2/private/zhx/bert/chinese/
output_dim = 15

[reader]
max_queue_size = 40
train_reader_num = 1
valid_reader_num = 1

[data]
formatter = SFKS_Bert_Subject

train_data_path = /data2/private/zhx/law/SFKS/data/origin_data/no
train_file_list = 0_train.json,1_train.json
valid_data_path = /data2/private/zhx/law/SFKS/data/origin_data/no
valid_file_list = 0_test.json,1_test.json

max_len = 512

need_word2vec = False

[output]
model_path = /data2/private/zhx/law/SFKS/model
model_name = Bert_subject
tensorboard_path = /data2/private/zhx/law/SFKS/tensorboard
test_time = 1
output_time = 1
