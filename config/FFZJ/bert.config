[train]
batch_size = 4
type_of_loss = multi_label_cross_entropy_loss

optimizer = adam
learning_rate = 1e-5

weight_decay = 0.01

gamma = 0.95
step_size = 11

multi = True

[model]
name = Bert

bert_path = /data/disk3/private/zhx/bert/chinese
output_dim = 30

[reader]
max_queue_size = 40
train_reader_num = 1
valid_reader_num = 1

[data]
formatter = FFZJBert

train_data_path = /data/disk1/private/zhx/ffzj/data
train_file_list = train.txt
valid_data_path = /data/disk1/private/zhx/ffzj/data
valid_file_list = valid.txt

max_len = 256

need_word2vec = False

[output]
model_path = /data/disk1/private/zhx/ffzj/model
model_name = Bert
tensorboard_path = /data/disk1/private/zhx/ffzj/tensorboard
test_time = 1
output_time = 1
