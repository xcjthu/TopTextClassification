[train]
batch_size = 64
type_of_loss = demo_multi_task_loss_without_attr


optimizer = adam
learning_rate = 2e-4

weight_decay = 1e-3
momentum = 1

gamma = 0.95
step_size = 5

pre_train = 0

epoch = 1024

[model]
name = DemoCNN

hidden_size = 256

min_gram = 2
max_gram = 5
filters = 32

[reader]
max_queue_size = 20
train_reader_num = 4
valid_reader_num = 4


[data]
formatter = DemoFormatter2


train_data_path = /data/disk1/private/xcj/demo/data/train_data
# train_file_list = 0.json,1.json,2.json,3.json,4.json,5.json,6.json,7.json,8.json,9.json,10.json,11.json,12.json,13.json,14.json,15.json,16.json,17.json,18.json,19.json,20.json,21.json,22.json,23.json,24.json

train_file_list = 0.json,1.json,2.json,3.json,4.json,5.json,6.json,7.json,8.json,9.json,10.json,11.json
valid_data_path = /data/disk1/private/xcj/demo/data/test_data
# valid_file_list = 0.json,1.json,2.json,3.json,4.json,5.json,6.json,7.json,8.json,9.json
valid_file_list = 0.json,1.json,2.json,3.json,4.json

max_len = 512

word2id = /data/disk3/private/zhx/exam/data/embedding/word2id5.txt

charge_label = /data/disk1/private/xcj/demo/data/charge.txt
law_label = /data/disk1/private/xcj/demo/data/law.txt
attribute_path = /data/disk1/private/xcj/demo/data/attribute.json


attrNum = 10
taskNum = 3
vec_size = 200
task_name = law,charge,time

need_word2vec = False


[output]
model_path = /data/disk1/private/xcj/demo/model
model_name = MultiTaskBert
tensorboard_path = /data/disk1/private/xcj/demo/tensorboard
test_time = 1
output_time = 1
