[train]
batch_size = 16
type_of_loss = demo_multi_task_loss_without_attr


optimizer = bert_adam
learning_rate = 1e-5

weight_decay = 1e-3
momentum = 1

gamma = 1
step_size = 3

pre_train = 0

epoch = 1024

[model]
name = BertDemo

hidden_size = 256

bert_path = /data/disk3/private/zhx/bert/law


[reader]
max_queue_size = 40
train_reader_num = 1
valid_reader_num = 1


[data]
formatter = DemoFormatter2

train_data_path = /data/disk1/private/xcj/demo/data/train_data
train_file_list = 0.json,1.json,2.json,3.json,4.json,5.json,6.json,7.json,8.json,9.json,10.json,11.json,12.json,13.json,14.json,15.json,16.json,17.json,18.json,19.json,20.json,21.json,22.json,23.json,24.json
valid_data_path = /data/disk1/private/xcj/demo/data/test_data
valid_file_list = 0.json,1.json,2.json,3.json,4.json,5.json,6.json,7.json,8.json,9.json


max_len = 512

word2id = /data/disk3/private/zhx/exam/data/embedding/word2id5.txt

charge_label = /data/disk5/private/zhx/demo/data/charge.txt
law_label = /data/disk5/private/zhx/demo/data/law.txt
attribute_path = /data/disk5/private/zhx/demo/data/attribute.json


attrNum = 10
taskNum = 3
vec_size = 200
task_name = law,charge,time

need_word2vec = False


[output]
model_path = /data/disk1/private/zhx/demo/model
model_name = bert1
tensorboard_path = /data/disk1/private/zhx/demo/tensorboard
test_time = 1
output_time = 1
