[train]
batch_size = 16
type_of_loss = demo_multi_task_loss_without_attr


optimizer = bert_adam
learning_rate = 1e-5

weight_decay = 1e-3
momentum = 1

gamma = 0.95
step_size = 3

pre_train = 0

epoch = 1024

[model]
name = BertDemo

hidden_size = 256

bert_path = /data/disk3/private/zhx/bert/chinese


[reader]
max_queue_size = 40
train_reader_num = 5
valid_reader_num = 3


[data]
formatter = DemoFormatter2


train_data_path = /data/disk5/private/zhx/demo/data/train
train_file_list = train.json
valid_data_path = /data/disk5/private/zhx/demo/data/test
valid_file_list = test.json


max_len = 512

word2id = /data/disk3/private/zhx/exam/data/embedding/word2id5.txt

charge_label = /data/disk5/private/zhx/demo/data/charge.txt
law_label = /data/disk5/private/zhx/demo/data/law.txt
attribute_path = /data/disk5/private/zhx/demo/data/attribute.json


attrNum = 10
taskNum = 3
vec_size = 200
task_name = law,charge,time

need_word2vec = False


[output]
model_path = /data/disk1/private/zhx/demo/model
model_name = bert2
tensorboard_path = /data/disk1/private/zhx/demo/tensorboard
test_time = 1
output_time = 1
